{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 1:** Feature extractors\n",
    "\n",
    "Although ORB is well known for being faster than other feature extractors, it has problems with some image variations, such as rotation and illumination. In such cases, it's a good idea to try different feature extraction methods and compare their results according to the found features and matches.\n",
    "\n",
    "This time, you will have to implement ORB, SIFT, AKAZE, BRISK, KAZE, and AGAST to find and match the keypoints of a training image and a query image. The images should be related to a famous building in Bolivia, however, most importantly, you should use two different pictures of the same building with different perspective. You also have to test the FLANN Feature Matcher, known for its better performance. Use the following link to understand the OpenCV implementations: https://docs.opencv.org/master/db/d27/tutorial_py_table_of_contents_feature2d.html\n",
    "\n",
    "SIFT and the other feature extractors might not be available for all OpenCV versions. Possibly, you will have to uninstall your current OpenCV version and install another version. For example, SIFT is available in `opencv-contrib-python==3.4.16.59` and `4.7.0.72`, which can be installed as follows.\n",
    "\n",
    "```\n",
    "!pip uninstall opencv-python\n",
    "!pip uninstall opencv-contrib-python\n",
    "!pip install opencv-contrib-python==3.4.16.59\n",
    "```\n",
    "\n",
    "In the end, you should obtain a table similar to the following:\n",
    "\n",
    "\\begin{array}{ccccccc}\n",
    "\\text{Feature Extractor}&\\text{Features found in Training Image}&\\text{Features found in Query Image}&\\text{Matches with BF}&\\text{Matches with FLANN}&\\text{Correct matches}\\\\\n",
    "SIFT              &                                  &                               &                 &                    &                 \\\\\n",
    "ORB               &                                  &                               &                 &                    &                 \\\\\n",
    "AGAST             &                                  &                               &                 &                    &  \\\\\n",
    "AKAZE             &                                  &                               &                 &                    &  \\\\\n",
    "AKAZE             &                                  &                               &                 &                    &      \\\\\n",
    "BRISK             &                                  &                               &                 &                    &        \\\\\n",
    "\\end{array}\n",
    "\n",
    "Try obtain the best results as possible varying the method's parameters. Finally, note that you have to count manually the correct keypoints matched in both images to fill in the final column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
